
@book{vonNeumann1944,
  author = {John von Neumann and Oskar Morgenstern},
  title = {Theory of Games and Economic Behavior},
  year = {1944},
  publisher = {Princeton University Press},
  address = {Princeton, NJ},
}

@misc{UCBContest2015,
  author = {{UC Berkeley}},
  title = {{Contest: Pacman Capture the Flag}},
  howpublished = {\url{http://ai.berkeley.edu/contest.html}},
  year = {2015}
}



@article{CAMPBELL200257,
title = {Deep Blue},
journal = {Artificial Intelligence},
volume = {134},
number = {1},
pages = {57-83},
year = {2002},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(01)00129-1},
url = {https://www.sciencedirect.com/science/article/pii/S0004370201001291},
author = {Murray Campbell and A.Joseph Hoane and Feng-hsiung Hsu},
keywords = {Computer chess, Game tree search, Parallel search, Selective search, Search extensions, Evaluation function},
abstract = {Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: •a single-chip chess search engine,•a massively parallel system with multiple levels of parallelism,•a strong emphasis on search extensions,•a complex evaluation function, and•effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decisions behind Deep Blue.}
}
@article{CAMPBELL1983347,
title = {A comparison of minimax tree search algorithms},
journal = {Artificial Intelligence},
volume = {20},
number = {4},
pages = {347-367},
year = {1983},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(83)90001-2},
url = {https://www.sciencedirect.com/science/article/pii/0004370283900012},
author = {Murray S. Campbell and T.A. Marsland},
abstract = {Although theoretic performance measures of most game-searching algorithms exist, for various reasons their practicality is limited. This paper examines and extends the existing search methods, and reports on empirical performance studies on trees with useful size and ordering properties. Emphasis is placed on trees that are strongly ordered, i.e., similar to those produced by many current game-playing programs.}
}

@article{RIVEST198777,
title = {Game tree searching by min/max approximation},
journal = {Artificial Intelligence},
volume = {34},
number = {1},
pages = {77-96},
year = {1987},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(87)90004-X},
url = {https://www.sciencedirect.com/science/article/pii/000437028790004X},
author = {Ronald L. Rivest},
abstract = {We present an iterative method for searching min/max game trees based on the idea of approximating the “min” and “max” operators by generalized mean-valued operators. This approximation is used to guide the selection of the next leaf node to expand, since the approximations allow one to select efficiently that leaf node upon whose value the (approximate) value at the root most highly depends. Experimental results from almost 1,000 games of Connect-Four11Connect-Four is a trademark of the Milton-Bradley company. suggest that our scheme is superior to minimax search with alpha-beta pruning, for the same number of calls to the move routine. However, our scheme has higher overhead, so that further work is needed before it becomes competitive when CPU time per turn is the limiting resource.}
}

@book{Hastie2009,
  author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  title = {The Elements of Statistical Learning},
  publisher = {Springer},
  year = {2009},
  address = {New York, NY},
  isbn = {978-0-387-84857-0}
}

@article{GELLY20111856,
title = {Monte-Carlo tree search and rapid action value estimation in computer Go},
journal = {Artificial Intelligence},
volume = {175},
number = {11},
pages = {1856-1875},
year = {2011},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2011.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S000437021100052X},
author = {Sylvain Gelly and David Silver},
keywords = {Computer Go, Monte-Carlo, Search, Reinforcement learning},
abstract = {A new paradigm for search, based on Monte-Carlo simulation, has revolutionised the performance of computer Go programs. In this article we describe two extensions to the Monte-Carlo tree search algorithm, which significantly improve the effectiveness of the basic algorithm. When we applied these two extensions to the Go program MoGo, it became the first program to achieve dan (master) level in 9×9 Go. In this article we survey the Monte-Carlo revolution in computer Go, outline the key ideas that led to the success of MoGo and subsequent Go programs, and provide for the first time a comprehensive description, in theory and in practice, of this extended framework for Monte-Carlo tree search.}
}